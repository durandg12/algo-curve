---
title: "A fast algorithm to compute a curve of confidence upper bounds for the False Discovery Proportion using a reference family with a forest structure"
# subtitle: ""
author:
  - name: Guillermo Durand
    corresponding: true
    email: guillermo.durand@universite-paris-saclay.fr
    url: https://durandg12.github.io/
    orcid: 0000-0003-4056-5631
    affiliations:
      - name: Université Paris-Saclay
        department: Laboratoire de Mathématiques d'Orsay
        url: https://www.imo.universite-paris-saclay.fr/fr/
date: last-modified
date-modified: last-modified
abstract: >+
  This paper presents a new algorithm (and an additional trick) that allows to compute fastly an entire curve of post hoc bounds for the False Discovery Proportion when the underlying bound $V^*_{\mathfrak{R}}$ construction is based on a reference family $\mathfrak{R}$ with a forest structure à la @MR4178188. By an entire curve, we mean the values $V^*_{\mathfrak{R}}(S_1),\dotsc,V^*_{\mathfrak{R}}(S_m)$ computed on a path of increasing selection sets $S_1\subsetneq\dotsb\subsetneq S_m$, $|S_t|=t$. The new algorithm leverages the fact that going from $S_t$ to $S_{t+1}$ is done by adding only one hypothesis.
keywords: [multiple testing, algorithmic, post hoc inference, false discovery proportion, confidence bound]
citation:
  type: article-journal
  container-title: "Computo"
  doi: "xxxx"
  url: https://computo.sfds.asso.fr/algo-curve
  publisher: "Société Française de Statistique"
  issn: "2824-7795"
bibliography: algo-curve.bib
github-user: durandg12
repo: "algo-curve"
draft: true # set to false once the build is running
published: false # will be set to true once accepted
number-sections: true
format:
  computo-html: 
    html-math-method: mathjax
    include-in-header:
      - text: |
          <script>
          window.MathJax = {
            tex: {
              tags: 'ams'
            }
          };
          </script>
    crossrefs-hover: true
  computo-pdf: 
    include-in-header:
      - text: |
          \usepackage{amsmath}
    cite-method: natbib
    natbiboptions: round
    keep-tex: true
    crossrefs-hover: true
---

::: {.hidden}
 \newcommand{\comp}[1]{{#1}^{\mathsf{c}}}
 \newcommand{\Pro}[1]{\mathbb{P}\left(#1\right)} 
 \newcommand{\Esp}[1]{\mathbb{E}\left[ #1 \right]}
 \newcommand{\ind}[1]{\mathbb{1}_{\left\{#1 \right\}}}
 \newcommand{\cH}{\mathcal{H}}
 \newcommand{\cK}{\mathcal{K}}
 \newcommand{\cP}{\mathcal{P}}
 \newcommand{\FDP}{\mathrm{FDP}}
 \newcommand{\FDR}{\mathrm{FDR}}
 \newcommand{\JER}{\mathrm{JER}}
 \newcommand{\Rfam}{\mathfrak{R}}
 \newcommand{\Hoi}{H_{0,i}}
 \newcommand{\Vhat}{\widehat V}
 \newcommand{\Vstar}{V^*_{\Rfam}}
 \newcommand{\Nm}{\mathbb{N}_m}
 \newcommand{\pr}{\mathfrak{pr}}
 \newcommand{\kth}[2]{k^{(#1,#2)}}
 \newcommand{\RR}{\mathbb{R}}
:::

# Introduction

Multiple testing theory is often used for exploratory analysis, like Genome-Wide Association Studies, where multiple features are tested to find promising ones. Classical multiple testing theory like Family-Wise Error Rate (FWER) control or False Discovery Rate (FDR) control [@MR1325392] can be used, but a more recent trend consists in the computation of post hoc bounds, also named post selection bounds or confidence envelopes, for the number of false positives, or, equivalently, for the False Discovery Proportion (FDP). This approach is notably advocated for in the context of exploratory research by [@MR2951390, Section 1]. 

Mathematically speaking, a confidence upper bound (we prefer to say upper bound instead of envelope for obvious reasons) is a function $\Vhat : \cP(\Nm^*) \to \Nm$, where $\Nm=\{0,\dotsc,m\}$, $\Nm^*=\{1,\dotsc,m\}$ and $m$ is the number of hypotheses, such that 
\begin{equation}
\forall \alpha \in ]0,1[, \Pro{\forall S \subseteq \Nm^*, |S\cap \cH_0|\leq \Vhat(S)}\geq 1-\alpha.
\label{eq_confidence}
\end{equation}
Here, $\alpha$ is a target error rate and $\cH_0$ is the set of hypotheses indices that are true null hypotheses. Note that the construction of $\Vhat$ depends on $\alpha$ and on the random data $X$ and the dependence is omitted to lighten notation and because there is no ambiguity. The meaning of Equation \eqref{eq_confidence} is that $\Vhat$ provides an upper bound of the number of null hypotheses in $S$ for any selection set $S\subseteq \Nm^*$, which allows the user to perform post hoc selection on their data without breaching the statistical guarantee. Also note that by dividing by $|S|\vee 1$ in Equation \eqref{eq_confidence} we also get a confidence bound for the FDP:
\begin{equation}
\forall \alpha \in ]0,1[, \Pro{\forall S \subseteq \Nm^*, \FDP(S)\leq \frac{\Vhat(S)}{|S|\vee 1}}\geq 1-\alpha.
\label{eq_confidence_fdp}
\end{equation}
So post hoc bounds provide ways to construct FDP-controlling sets instead of FDR-controlling sets, which is much more desirable given the nature of the FDR as an expected value. See for example [@MR3418717, Figure 4] for a credible example where the FDR is controlled but the FDP has a highly undesirable behavior (either 0 because no discoveries at all are made, either higher than the target level).

The first confidence bounds are found in @MR2279468 and @MR2279639, although, in the latter, only for selection sets of the form $\{i\in\Nm : P_i\leq t\}$ where $P_i$ is the $p$-value associated to the null hypothesis $\Hoi$. In @MR2951390 the authors re-wrote the generic construction of @MR2279468 in terms of closed testing @MR468056, proposed several practical constructions and sparked a new interest in multiple testing procedures based on confidence envelopes. This work was followed by a prolific series of works like @MR3305943 and @MR4731977. In @MR4124323, the authors introduce the new point of view of references families (see @sec-reference-fam) to construct post hoc bounds, and show the links between this meta-technique and the closed testing one, along with new bounds. 

Following the reference family trail, in @MR4178188 the authors introduce new reference families with a special set-theoretic constraint that allows an efficient computation of the bound denoted by $\Vstar$ on a single selection set $S$. The problem is that one often wants to compute $\Vstar$ on a whole path of selection sets $(S_t)_{t\in\Nm^*}$, for example the hypotheses attached to the $t$ smallest $p$-values. Whereas the algorithm provided in the aforementioned work [@MR4178188, Algorithm 1] <!--which is reproduced here, see @ref--> is fast for a single evaluation, it is slow and inefficient to repeatedly call it to compute each $\Vstar(S_t)$. If the $S_t$'s are nested, and growing by one, that is $S_1\subsetneq\dotsb\subsetneq S_m$ and $|S_t|=t$, there is a way to efficiently compute $\left(\Vstar(S_t)\right)_{t\in\Nm}$ by leveraging the nested structure. 

This is the main contribution of the present paper: a new and fast algorithm computing the curve $\left(\Vstar(S_t)\right)_{t\in\Nm}$ for a nested path of selection sets, that is presented in @sec-fast-curve. An additional algorithm that can speed up computations both for the single-evaluation algorithm and the new curve-evaluation algorithm is also presented, in @sec-pruning. In @sec-notation, all necessary notation and vocabulary is re-introduced, most of it being the same as in @MR4178188. Finally, a few numerical experiments are presented in Section @sec-numeric to demonstrate the computation time gain.

# Notation and reference family methodology

## Multiple testing notation {#sec-notation}

As is usual in multiple testing theory, we consider a probability space $(\Omega,\mathcal A, \mathbb P)$, a model $\mathcal{P}$ on a measurable space $(\mathcal{X},\mathfrak{X})$, and data that is represented by a random variable $X:(\Omega,\mathcal A)\to(\mathcal{X},\mathfrak{X})$ with $X\sim P\in \mathcal{P}$, that is, the law of $X$ is comprised in the model $\mathcal{P}$.

Then we consider $m\geq1$ null hypotheses $H_{0,1}, \dotsc, H_{0,m}$ which formally are submodels, that is subsets of $\mathcal{P}$. The associated alternative hypotheses $H_{1,1}, \dotsc, H_{1,m}$ are submodels such that $\Hoi\cap H_{1,i}=\varnothing$ for all $i\in\Nm^*$. We denote by $\cH_0=\cH_0(P)$ (the dependence in $P$ will be dropped when there is no ambiguity) the set of all null hypotheses that are true, that is $\cH_0(P)=\{i\in\Nm^* : P\in \Hoi\}$. In other words, $\Hoi$ is true if and only if $i\in\cH_0$. For testing each $\Hoi, i\in\Nm^*$, we have at hand a $p$-value $p_i=p_i(X)$ (the dependence in $X$ will be dropped when there is no ambiguity) which is a random variable with the following property : if $i\in\cH_0$, then the law of $p_i$ is super-uniform, which is sometimes denoted $\mathcal L(p_i)\succeq \mathcal{U}([0,1])$. This means that in such case, the cumulative distribution function (cdf) of $p_i$ is always smaller than or equal to the cdf of a random variable $U\sim \mathcal{U}([0,1])$ :
\begin{equation}
\forall x \in \RR, \Pro{p_i\leq x}\leq \Pro{U\leq x} = 0\vee(x\wedge 1).
\label{eq_super_unif}
\end{equation}

For every subset of hypotheses $S\subseteq\Nm^*$, let $V(S)=|S\cap\cH_0|$. If we think of $S$ as a selection set of hypotheses deemed significant, $V(S)$ is then the number of false positives (FP) in $S$. $V(S)$ is our main object of interest and the quantity that we wish to over-estimate with confidence upper bounds (see Equation \eqref{eq_confidence} or the more formal Equation \eqref{eq_confidence_formal}).

Finally let us consider the following toy example, that will be re-used in the remainder of the paper.

::: {#exm-gauss}

## Gaussian one-sided

In this case we assume that $X=(X_1,\dotsc,X_m)$ is a Gaussian vector and the null hypotheses refer to the nullity of the means in contrast to their positivity. That is, formally, $(\mathcal{X},\mathfrak{X})=(\mathbb R^m, \mathcal B\left(\mathbb R^m  \right))$, $\mathcal P=\{ \mathcal N(\boldsymbol{\mu}, \Sigma) : \forall j \in\Nm^*, \mu_j\geq 0, \Sigma \text{ positive semidefinite}  \}$, for each $i\in\Nm^*$, $\Hoi= \{ \mathcal N(\boldsymbol{\mu}, \Sigma) \in \mathcal P :\mu_i=0 \}$ and $H_{1,i}=\{ \mathcal N(\boldsymbol{\mu}, \Sigma) \in \mathcal P :\mu_i>0 \}$. Then we can construct $p$-values by letting $p_i(X)=\bar\Phi(X_i)=1-\Phi(X_i)$, where $\Phi$ denotes the cdf of $\mathcal N(0,1)$ and $\bar\Phi$ the associated survival function.
:::

## Post hoc bounds with reference families {#sec-reference-fam}

With the formalism introduced in last section, a confidence upper bound is a functional $\Vhat :\mathcal X\times ]0,1[\to(\mathcal P(\Nm^*) \to \Nm)$  such that,
\begin{equation}
\forall P\in\mathcal P, \forall X\sim P, \forall \alpha \in ]0,1[, \Pro{\forall S \subseteq \Nm^*, V(S)\leq \Vhat(X,\alpha)(S)}\geq 1-\alpha.
\label{eq_confidence_formal}
\end{equation}
In the remainder, the dependence in $(X,\alpha)$ will be dropped when there is no ambiguity and $\Vhat(X,\alpha)$ will simply be written $\Vhat$.

As said in the Introduction, many constructions, ultimately theoretically equivalent but differing by the practical steps involved, exist, and in this paper we focus on the meta-construction of @MR4124323 based on reference families. A reference family is a family $\Rfam=\Rfam(X,\alpha)=(R_k,\zeta_k)_{k\in \mathcal K}$ with $|\mathcal K|\leq 2^m$, $R_k\subseteq\Nm^*$, $\zeta_k\in\left\{0,\dotsc,|R_k|\right\}$ where everything (that is, $\mathcal K$ and all the $R_k$ and $\zeta_k$) depends on $(X,\alpha)$ but the dependency is not explicitly written. We also define the following error criterion for a reference family, named Joint Error Rate (JER):
\begin{equation}
\JER(\Rfam) = \Pro{\exists k\in\mathcal K, |R_k\cap\cH_0| > \zeta_k } = \Pro{\exists k\in\mathcal K, V(R_k) > \zeta_k }.
\label{eq_jer}
\end{equation}
In the following, we are only interested in reference families that control the JER at level $\alpha$:
\begin{equation}
\forall P\in\mathcal P, \forall X\sim P, \forall \alpha \in ]0,1[, 1-\JER(\Rfam(X,\alpha))=\Pro{\forall k\in\mathcal K, V(R_k)\leq \zeta_k} \geq 1-\alpha.
\label{eq_jer_control}
\end{equation}
Note that Equation \eqref{eq_jer_control} is really similar to Equation \eqref{eq_confidence_formal} except that the uniform guarantee, instead of being over all $S\subseteq \Nm^*$, is only over all the $R_k\subseteq \Nm^*, k\in\mathcal K$, with $\mathcal K$ having cardinality potentially much smaller than $2^m$. A global confidence bound is then derived from a JER-controlling reference family by interpolation. Let 
\begin{equation}
\mathcal A(\Rfam)= \left\{A\subseteq \Nm^*:  \forall k\in\mathcal K, |R_k\cap A| \leq \zeta_k \right\}.
\label{eq_a}
\end{equation}
What says the JER control is that $\cH_0\in\mathcal A(\Rfam)$. We leverage this information with the following confidence bound construction:
\begin{equation}
\Vstar(S) = \max_{A\in\mathcal A(\Rfam)}|S\cap A|
\label{eq-vstar}
\end{equation}
which optimally uses the information provided by the JER control of the reference family, as proven by Proposition 2.1 of @MR4124323. Because of the $\max_{A\in\mathcal A(\Rfam)}$, the computation of $\Vstar(S)$ is generally intractable (see Proposition 2.2 of @MR4124323), but for specific structures of reference families, a polynomial computation can be derived. This is the topic of @MR4178188 and of next section.

## Regions with a forest structure

The core concept of this section is to assume that the regions $R_k$'s of the reference family are what we called in @MR4178188 a forest structure, that is two regions are either disjoint or nested:
\begin{equation}
\forall k,k'\in\mathcal{K} , R_k \cap R_{k'} \in \{ R_k,  R_{k'} , \varnothing \}.
\label{eq-forest}
\end{equation}
Representing the $R_k$'s with a directed graph, where there is an oriented edge $R_k \leftarrow R_{k'}$ if and only if $R_k \subset R_{k'}$ and there is no $R_{k''}$ such that $R_k \subsetneq R_{k''}\subsetneq R_{k'}$ gives a forest, hence the name. See @exm-toy-forest and its representation in @fig-forest-exm.

We also need to introduce the notion of depth with the following function:
\begin{equation}
\phi \:  : \: \left\{
\begin{array}{l  c l  }
 \cK & \to & \mathbb{N}^*\\
k & \mapsto & 1 + \left| \{k'\in\cK: R_k\subsetneq R_{k'} \} \right|   .
\end{array}
\right.
\label{eq-depth}
\end{equation}

::: {#exm-toy-forest}

Let $m=25$, $R_1 = \{1, \dotsc , 20 \}$, $R_2  =  \{1, 2  \}$, $R_3   =   \{3 , \dotsc , 10 \}$, $R_4  =    \{11, \dotsc , 20 \}$, $R_5 =  \{5, \dotsc , 10 \}$, $R_6   =     \{11, \dotsc , 16 \}$, $R_7  =   \{17, \dotsc ,20  \}$, $R_8=\{21,22\}$, $R_9 = \{22\}$. This is the same example as Example 2 of @MR4178188 and it is graphically depicted in @fig-forest-exm. The sets $R_1$, $R_8$ are of depth $1$; the sets $R_2,R_3,R_4,R_9$ are of depth $2$; the sets $R_5,R_6,R_7$ are of depth $3$.
:::

:::{#fig-forest-exm}

``` {.tikz opt-additional-packages="\usetikzlibrary{arrows}"}
\begin{tikzpicture}[scale=0.85]
 \tikzstyle{quadri}=[circle,draw,text=black, thick]
 \tikzstyle{estun}=[->,>=latex,very thick]
 \node[quadri] (R1) at (0,3) {$R_1$};
 \node[quadri] (R2) at (-2,1) {$R_2$};
 \node[quadri] (R3) at (0,1) {$R_3$};
 \node[quadri] (R4) at (2,1) {$R_4$};
 \node[quadri] (R5) at (0,-1) {$R_5$};
 \node[quadri] (R6) at (1.5,-1) {$R_6$};
 \node[quadri] (R7) at (2.5,-1) {$R_7$};
 \node[quadri] (R8) at (4,3) {$R_8$};
 \node[quadri] (R9) at (4,1) {$R_9$};
 \draw[estun] (R1)--(R2);
 \draw[estun] (R1)--(R3);
 \draw[estun] (R1)--(R4);
 \draw[estun] (R3)--(R5);
 \draw[estun] (R4)--(R6);
 \draw[estun] (R4)--(R7);
 \draw[estun] (R8)--(R9);
\end{tikzpicture}
```

The regions of @exm-toy-forest.

:::

Another tool of @MR4178188 that will be used is its Lemma 2, that is the identification of $\Rfam$ with a set $\mathcal C\subset \left\{(i,j)\in \left({\mathbb N_N}^*\right)^2 \: : i\leq j\right\}$ such that for $(i,j), (i',j')\in\mathcal C$, $\{i,\dotsc, j\}\cap\{i',\dotsc,j'\}\in\left\{\varnothing, \{i,\dotsc, j\},\{i',\dotsc j'\}  \right\}$. With this identification, each $R_k=R_{(i,j)}$ can be written as $P_{i:j}=\bigcup_{i\leq n\leq j}P_n$ where $(P_n)_{1\leq n \leq N}$ is a partition of $\Nm^*$. The $P_n$'s were called atoms in @MR4178188 because they have the thinnest granularity in the structure, but to continue the analogy with graphs, forests and trees, they can also be called leafs. See @exm-toy-leaves for a concrete example.

::: {#exm-toy-leaves}

## Continuation of @exm-toy-forest

For the reference family given in @exm-toy-forest, a partition of atoms is given by $P_1 =R_2$, $P_2  =   R_3\setminus R_5$, $P_3  =   R_5$, $P_4=R_6$, $P_5=R_7$, $P_6=R_8\setminus R_9$, $P_7=R_9$, $P_8=\Nm^* \setminus \{R_1 \cup R_8 \}$. Then $R_1=P_{1:5}$, $R_3=P_{2:3}$, $R_4=P_{4:5}$ and $R_8=P_{6:7}$. Note that not all atoms are regions of the family. Those new labels are graphically depicted in @fig-leaves-exm. The nodes that correspond to atoms that are not in the family are depicted with a dashed circle. This is the same example as Example 3 of @MR4178188.
:::

:::{#fig-leaves-exm}

``` {.tikz opt-additional-packages="\usetikzlibrary{arrows}"}
\begin{tikzpicture}[scale=0.85]
 \tikzstyle{quadri}=[circle,draw,text=black,thick]
 \tikzstyle{estun}=[->,>=latex,very thick]
 \node[quadri] (R1) at (0,3) {$P_{1:5}$};
 \node[quadri, fill=gray!25] (R2) at (-2,1) {$P_1$};
 \node[quadri] (R3) at (0,1) {$P_{2:3}$};
 \node[quadri] (R4) at (2,1) {$P_{4:5}$};
 \node[quadri, dashed,fill=gray!25] (P2) at (-0.5,-1) {$P_2$};
 \node[quadri,fill=gray!25] (R5) at (0.5,-1) {$P_3$};
 \node[quadri,fill=gray!25] (R6) at (1.5,-1) {$P_4$};
 \node[quadri,fill=gray!25] (R7) at (2.5,-1) {$P_5$};
 \node[quadri] (R8) at (4,3) {$P_{6:7}$};
 \node[quadri,dashed,fill=gray!25] (P6) at (3.5,1) {$P_6$};
 \node[quadri,fill=gray!25] (R9) at (4.5,1) {$P_7$};
 \node[quadri,dashed,fill=gray!25] (P8) at (6,3) {$P_8$};
 \draw[estun] (R1)--(R2);
 \draw[estun] (R1)--(R3);
 \draw[estun] (R1)--(R4);
 \draw[estun] (R3)--(R5);
 \draw[estun,dashed,thick] (R3)--(P2);
 \draw[estun] (R4)--(R6);
 \draw[estun] (R4)--(R7);
 \draw[estun] (R8)--(R9);
 \draw[estun,dashed,thick] (R8)--(P6);
\end{tikzpicture}
```

The regions of @exm-toy-forest but with the labels of @exm-toy-leaves.

:::

When all leaves are regions of the family, it is said that the family is complete. If this is not the case, the family can easily be completed by adding the missing leaves (and using their cardinality as associated $\zeta$) without changing the value $\Vstar$. See Definition 2 and Lemma 6 of @MR4178188 for the details.

@MR4178188 also prove in their Theorem 1 that: 
\begin{equation}
V^*_{\Rfam}(S)=\min_{Q\subseteq\cK}\left(\sum_{k'\in Q}\zeta_{k'}\wedge|S\cap R_{k'}|+\left| S\setminus\bigcup_{k'\in Q} R_{k'}   \right|\right)
\label{eq_vstar_Q} 
\end{equation}
and, even better, in their Corollary 1 *(iii)* that:
\begin{equation}
\Vstar(S) = \min_{Q\in \mathfrak P}\sum_{k'\in Q}\zeta_{k'}\wedge|S\cap R_{k'}|,
\label{eq_vstar_Qpartition}
\end{equation}
provided that the family is complete. Here, $\mathfrak P \subseteq \mathcal P(\cK)$ is the set of subsets of $\cK$ that realize a partition, that is, the set of $Q\subseteq\cK$ such that the $R_k$, $k\in Q$, form a partition of $\Nm^*$. So the minimum in Equation \eqref{eq_vstar_Qpartition} is over way less elements than in Equation \eqref{eq_vstar_Q}.

Finally, that paper provides a polynomial algorithm to $V^*_{\Rfam}(S)$ for a single $S\subseteq\Nm^*$, which we reproduce here in @alg-vstar. The family is assumed complete, otherwise the first step would be to complete it. In the original paper, $\cK^h$ used to designate the elements of $\cK$ at depth $h$ plus the atoms at depth $\leq h$. Actually one can realize that the last assumption is not needed for this algorithm to perform exactly the same, with the added benefit of not repeating computations at the atoms that don't have the maximal depth. The only change is that sometimes $Succ_k$ can be empty, in which case we simply let $newVec_k=\zeta_k\wedge|S\cap R_k|$. Thus, here, we can define $\cK^h$ as only the elements of $\cK$ at depth $h$ (the previous intricate definition may still be necessary for the proof of Theorem 1 of @MR4178188): $\cK^h=\{ (i,j)\in\cK : \phi(i,j)=h      \}, \:\:\:h\geq 1.$ Note that in the ongoing analogy with graph theory, the elements of $\cK^1$ are the roots of the different trees making up the forest.

```pseudocode
#| label: alg-vstar
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-placement: "htb!"
#| pdf-line-number: true
\begin{algorithm}
\caption{Computation of a given $\Vstar(S)$}
\begin{algorithmic}
\Procedure{Vstar}{S, $\mathfrak{R}=(R_{k},\zeta_{k})_{k\in\mathcal{K}}$  with $\mathfrak{R}$ complete}
  \State $ H \gets \max_{k\in\mathcal{K}} \phi(k)  $ \Comment{maximum depth}
  \For{$h = H-1, \dotsc, 1$}
    \State $\mathcal{K}^h\gets \{ k\in\mathcal{K} : \phi(k) =h  \}$
    \State $newVec\gets (0)_{k \in  \mathcal{K}^h}$
    \For{$k \in  \mathcal{K}^h$}
      \State $Succ_k \gets \{ k' \in  \mathcal{K}^{h+1} : R_{k'}\subseteq R_k\}$
      \If{$Succ_k=\varnothing$}
        \State $newVec_k \gets \zeta_k\wedge|S\cap R_k|$
      \Else
        \State $newVec_k \gets \min\left( \zeta_{k}\wedge|S\cap R_k| ,  \sum_{k'\in Succ_k} Vec_{k'}   \right)$
      \EndIf
    \EndFor
    \State $Vec\gets newVec$
  \EndFor
  \State\Return $\sum_{k\in\mathcal{K}^1} Vec_k  $
\EndProcedure
\end{algorithmic}
\end{algorithm}
```
::: {.callout-tip}

In the practical implementation of this algorithm (and of the following @alg-pruning), $Vec$ and $newVec$ are always of size $N$ (the number of leaves) instead of the cardinality of $\cK^h$. And the sum $\sum_{k'\in Succ_k} Vec_{k'}$ is really easy to compute: if $R_k= R_{(i_0,i_{p}-1)}= \bigcup_{ j=0}^{p-1} R_{(i_{ j}, i_{ j+1}-1)}=\bigcup_{i_0\leq n\leq i_{p}-1}P_n\in\cK^h$ for some $p\geq2$, a strictly increasing sequence $(i_0,\dotsc,i_{p})$ and $R_{(i_{ j-1}, i_{ j}-1)}\in\cK^{h+1}$ for all $1\leq j\leq p$, then we simply sum $Vec$ over the indices from $i_{0}$ to $i_{p}-1$. After that, the computed quantity is set in $newVec$ at index $i_0$. So actually computing $Succ_k$ is not needed and not done.
:::

::: {#rem-zeta}

The specific computation of the $R_k$'s and the $\zeta_k$'s such that Equation \eqref{eq_jer_control} holds is outside the scope of the present paper, but different computations can be found in @MR4124323, @MR4178188 or <!--notip--> for example.

:::

# New algorithms

## Pruning the forest {#sec-pruning}

We remark the simple fact that if, for example, $(1,1), (2,2), (1,2)\in\cK$, and $\zeta_{(1,2)}\geq \zeta_{(1,1)}+\zeta_{(2,2)}$, then $R_{(1,2)}$ never contributes to the computation of any $\Vstar(S)$ and it could just be removed from $\Rfam$. We now formalize and prove this pruning scheme.

We define by $\cK^{\pr}$ ($\cK$ pruned) the set of elements of $\cK$ such that we removed all $(i,i')$ such that there exists $p\geq2$ and integers $i_1,\dotsc,i_{p-1}$ such that, when setting $i_0=i$ and $i_{p}=i'+1$, the sequence $(i_0,\dotsc,i_{p})$ is strictly increasing, $(i_{j-1},i_{j}-1)\in\cK$ for all $1\leq j\leq p$ and finally $\zeta_{(i,i')}=\zeta_{(i_0,i_{p}-1)}\geq \sum_{j=0}^{p-1} \zeta_{(i_j, i_{j+1}-1)}$. 

An important note is that for a removed $(i,i')\in\cK\setminus\cK^{\pr}$, we can always choose the indices $i_1,\dotsc,i_{p-1}$ such that actually $(i_j,i_{j+1}-1)\in\cK^{\pr}$ and not only $\cK$, because if  $(i_j,i_{j+1}-1)\in\cK\setminus\cK^{\pr}$ it can itself be fragmented, and this decreasing recursion eventually ends (the later possible being at the atoms of the forest structure). Also note that removing elements from $\cK$ does not alter the fact that we have at hand a forest structure, that is, the reference family defined by $\Rfam^{\pr}=(R_k,\zeta_k)_{k\in\cK^{\pr}}$ has a forest structure. Because pruning a forest structure does not touch the atoms, note finally that if $\cK$ is complete then so is $\cK^{\pr}$.

The following proposition states that pruning the forest does not alter the bound.<!--, so by pruning we get a computational advantage (because $\cK^{\pr}$ is smaller than $\cK$) without any theoretical loss.-->

::: {#prp-pruning}

## Pruning

For any $S\subseteq \Nm^*$, $\Vstar(S)=V^*_{\Rfam^{\pr}}(S)$.

:::

::: {.proof}

Recall Equation \eqref{eq_vstar_Q} and, because $\Rfam^{\pr}$ also has a forest structure,
\begin{equation}
V^*_{\Rfam^{\pr}}(S)=\min_{Q\subseteq\cK^{\pr}}\left(\sum_{k'\in Q}\zeta_{k'}\wedge|S\cap R_{k'}|+\left| S\setminus\bigcup_{k'\in Q} R_{k'}   \right|\right),
\label{eq_vstarpruned_Q}
\end{equation}
so we immediately get that $V^*_{\Rfam}(S)\leq V^*_{\Rfam^{\pr}}(S)$. 

Let any $Q\subseteq \cK$. We split $Q$ in $A$ elements of $\cK\setminus\cK^{\pr}$, denoted $(i_{0,a}, i_{p_a,a}-1)$, $1\leq a\leq A$ for some $p_a\geq2$, and $B$ elements of $\cK^{\pr}$, simply denoted $k_b$, $1\leq b\leq B$. By the definition of $\cK^{\pr}$ and the previous remarks, for any $1\leq a \leq A$, there exist integers $i_{1,a},\dotsc,i_{p_a-1,a}$ such that $i_{0,a}<i_{1,a}<\dotsb<i_{p_a-1,a} < i_{p_a,a}$, $(i_{j-1,a},i_{j,a}-1)\in\cK^{\pr}$ for all $1\leq j\leq p_a$, and $\zeta_{(i_{0,a}, i_{p_a,a}-1)}\geq \sum_{j=1}^{p_a}\zeta_{(i_{j-1,a},i_{j,a}-1)}$. Now let
\begin{equation}
Q^{\pr}=\{k_b : 1\leq b\leq B \} \cup \{ (i_{j-1,a},i_{j,a}-1) :  1\leq a\leq A, 1\leq j\leq p_a  \}.
\label{eq_Qpr}
\end{equation}
We have that $Q^{\pr}\subseteq \cK^{\pr}$ and $\bigcup_{k\in Q}R_k=\bigcup_{k\in Q^{\pr}}R_k$. Then,

:::

```pseudocode
#| label: alg-pruning
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-placement: "htb!"
#| pdf-line-number: true
\begin{algorithm}
\caption{Pruning of $\mathfrak{R}$}
\begin{algorithmic}
\Procedure{Pruning}{$\mathfrak{R}=(R_{k},\zeta_{k})_{k\in\mathcal{K}}$  with $\mathfrak{R}$ complete}
  \State $\mathcal{K}^{\mathfrak{pr}}\gets\mathcal{K}$
  \State $ H \gets \max_{k\in\mathcal{K}} \phi(k)  $ \Comment{maximum depth}
  \For{$h = H-1, \dotsc, 1$}
    \State $\mathcal{K}^h\gets \{ k\in\mathcal{K} : \phi(k) =h  \}$
    \State $newVec\gets (0)_{k \in  \mathcal{K}^h}$
    \For{$k \in  \mathcal{K}^h$}
      \State $Succ_k \gets \{ k' \in  \mathcal{K}^{h+1} : R_{k'}\subseteq R_k\}$
      \If{$Succ_k=\varnothing$}
        \State $newVec_k \gets \zeta_k$
      \Else
        \If{$\zeta_{k} \geq  \sum_{k'\in Succ_k} Vec_{k'}$}
          \State $\mathcal{K}^{\mathfrak{pr}}\gets \mathcal{K}^{\mathfrak{pr}}\setminus \{ k \}$
        \EndIf
        \State $newVec_k \gets \min\left( \zeta_{k} ,  \sum_{k'\in Succ_k} Vec_{k'}   \right)$
      \EndIf
    \EndFor
    \State $Vec\gets newVec$
  \EndFor
  \State\Return $(\mathcal{K}^{\mathfrak{pr}},\sum_{k\in\mathcal{K}^1} Vec_k  )$
\EndProcedure
\end{algorithmic}
\end{algorithm}
```


## Fast algorithm to compute a curve of confidence bounds on a path of selection sets {#sec-fast-curve}

::: {#thm-curve-path}

## Fast curve computation

:::

::: {.proof}

Content
:::

::: {#cor-easy-impl}

## Easy implementation

:::

```pseudocode
#| label: alg-formal-curve
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-placement: "htb!"
#| pdf-line-number: true
\begin{algorithm}
\caption{Formal computation of $(V^*_{\mathfrak{R}}(S_t))_{0\leq t\leq m}$}
\begin{algorithmic}
\Procedure{Curve}{$\mathfrak{R}=(R_{k},\zeta_{k})_{k\in\mathcal{K}}$  with $\mathfrak{R}$ complete, path $(S_t)_{1\leq t \leq m}$ with $S_t=\{i_1, \dotsc, i_t\}$}
  \State $\mathcal{P}^0\gets\{(i,i): 1\leq i \leq n\}$ \Comment{the set of all atoms indices}
  \State $\mathcal{K}^-_0\gets\{k\in\mathcal{K} : \zeta_k=0  \}$
  \State $\eta^0_k\gets0$ for all $k\in\mathcal{K}$
  \For{$t=1,\dotsc, m$}
    \If{$i_t\in\bigcup_{k\in\mathcal{K}^-_{t-1}}R_k$}
      \State $\mathcal{P}^t \gets \mathcal{P}^{t-1}$
      \State $\mathcal{K}^-_t \gets \mathcal{K}^-_{t-1}$
      \State $\eta^t_k\gets\eta^{t-1}_k$ for all $k\in\mathcal{K}$
    \Else
      \For{$h=1,\dotsc,h_{\max}(t)$}
        \State $\eta^t_{k^{(t,h)}}\gets\eta^{t-1}_{k^{(t,h)}} + 1$
        \If{$\eta^t_{k^{(t,h)}}<\zeta_k$}
          \State Pass
        \Else
          \State $h^f_t \gets h$.
          \State $\mathcal{P}^t \gets\left( \mathcal{P}^{t-1}\setminus \{ k\in \mathcal{P}^{t-1} : R_k\subseteq R_{k^{(t,h^f_t)}} \}\right)\cup \{ k^{(t,h^f_t)} \}$
          \State $\mathcal{K}^-_t \gets \mathcal{K}^-_{t-1} \cup \{k^{(t,h^f_t)}\}$
          \State Break the loop
        \EndIf
      \EndFor
      \If{the loop has been broken}
        \State $\eta^t_k\gets\eta^{t-1}_k$ for all $k\in\mathcal{K}$ not visited during the loop, that is all $k\not\in\{k^{(t,h)}, 1\leq h\leq h^f_t   \}$
      \Else
        \State $\mathcal{P}^t \gets \mathcal{P}^{t-1}$
        \State $\mathcal{K}^-_t \gets \mathcal{K}^-_{t-1}$
        \State $\eta^t_k\gets\eta^{t-1}_k$ for all $k\in\mathcal{K}$ not visited during the loop, that is all $k\not\in\{k^{(t,h)}, 1\leq h\leq h_{\max}(t)   \}$
      \EndIf
    \EndIf
  \EndFor
  \State\Return $\mathcal{P}^t, \eta^t_k$ for all $t=1,\dotsc, m$ and $k\in\mathcal{K}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
```


```pseudocode
#| label: alg-curve
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-placement: "htb!"
#| pdf-line-number: true
\begin{algorithm}
\caption{Implementation of $(V^*_{\mathfrak{R}}(S_t))_{0\leq t\leq m}$}
\begin{algorithmic}
\Procedure{Curve}{$\mathfrak{R}=(R_{k},\zeta_{k})_{k\in\mathcal{K}}$  with $\mathfrak{R}$ complete, path $(S_t)_{1\leq t \leq m}$ with $S_t=\{i_1, \dotsc, i_t\}$}
  \State $V_0\gets 0$
  \State $\mathcal{K}^-\gets\{k\in\mathcal{K} : \zeta_k=0  \}$
  \State $\eta_k\gets 0$ for all $k\in\mathcal{K}$
  \For{$t=1,\dotsc, m$}
    \If{$i_t\in\bigcup_{k\in\mathcal{K}^-}R_k$}
      \State $V_{t}\gets V_{t-1}$
    \Else
      \For{$h=1,\dotsc,h_{\max}(t)$}
        \State find $k^{(t,h)}\in\mathcal{K}^{h}$ such that $i_t\in R_{k^{(t,h)}}$
        \State $\eta_{k^{(t,h)}}\gets\eta_{k^{(t,h)}} + 1$
        \If{$\eta_{k^{(t,h)}}<\zeta_k$}
          \State pass
        \Else
          \State $\mathcal{K}^- \gets \mathcal{K}^-\cup \{ k^{(t,h)} \}$
          \State break the loop
        \EndIf
      \EndFor
     \State $V_{t}\gets V_{t-1} + 1$
    \EndIf
  \EndFor
  \State\Return $(V_t)_{1\leq t \leq m}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
```

# Numerical experiments {#sec-numeric}

# Conclusion

# Acknowledments

This work has been supported by ANR-20-IDEES-0002 (PIA), ANR-19-CHIA-0021 (BISCOTTE), ANR-23-CE40-0018 (BACKUP) and ANR-21-CE23-0035 (ASCAI).

# References {.unnumbered}

::: {#refs}
:::

# Session information {.appendix .unnumbered}

```{r session-info}
sessionInfo()
```

